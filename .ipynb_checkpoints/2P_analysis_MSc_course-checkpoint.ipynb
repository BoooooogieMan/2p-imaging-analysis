{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c73cb545-b42b-405c-869b-2b4b72a20f12",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analysis of 2-photon calcium imaging data\n",
    "\n",
    "This part of the course will guid you through the analysis of 2 Photon calcium imaging data.\n",
    "Before, you recorded the response of a specific neuron type (e.g, Tm9-lexA>>lexAop-GCaMP6f) while the fly was shown some visual stimulali (e.g. sine wave gratings of 5 different luminances). Now we want to analyse this data and visualize responses of individual neurons. The following steps are necessary:\n",
    "\n",
    "1. Movement correction\n",
    "2. Pre-analysis (Folder structure)\n",
    "3. Region of Intrest (ROI) selection\n",
    "4. Background subtraction\n",
    "5. df/f calculation and trial average\n",
    "6. SNR (Signal to Noise Ratio) and Reliability calculation\n",
    "7. Stimulus-dependent analysis\n",
    "8. Saving analysed data\n",
    "9. Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc83083-e6c4-4282-97e2-99e2a7cdb062",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Movement correction\n",
    "\n",
    "Movement correction is important to get rid of small movements of the brain and stabilize the recording in X and Y dimentions.\n",
    "During this process, the single image frames (e.g., TIFF files) from the microscope are aligned and collected into one TIFF stack, which is then used for further analysis.\n",
    "\n",
    "There are several option to correct for motion (see README.md file of the repository), including the usage of the well-known software IMAGEJ/FIJI.\n",
    "\n",
    "If you wanna try yourself, you could use an ImageJ macro with the plugin *Image Stabilizer*, which is based on the Lucas-Kanade optical flow algorithm. This algorithm estimates geometrical transformation based on spacial intensity information of two consecutive images and predicts the best alignment between them.\n",
    "\n",
    "To give you an example of the effect of Motion alignment please follow this link: https://www.cs.cmu.edu/~kangli/code/Image_Stabilizer.html\n",
    "\n",
    "\n",
    "#### How to do it yourself:\n",
    "\n",
    "- Open ImageJ\n",
    "- Open the macro with the file **Batch_imagestabilizer_MSc_course.ijm**\n",
    "- Check within the macro the data path to save the aligned TIFF stack:\n",
    "    `saveAs(\"TIFF... \", \"path_to_save\"+replace(subdir,\"/\",\"\")+\"_Ch2_reg.tif\");`\n",
    "- Run the macro with Strg+R (or go to Macros -> Run Macro or just Run, depending on which version you have)\n",
    "- Now select a folder of a single fly that has all the TSeries inside\n",
    "- When it is finished, the aligned files are in the location you specified before and can be sorted to the corresponding TSeries. (The files need to be sorted first before the next fly can be aligned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2a597f-6807-4290-804b-ec5bdd462e5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Pre-analysis (Folder structure)\n",
    "\n",
    "Before we can start with the next step of the analysis, we need to make sure that our data is in the right location.\n",
    "Please create the following folder structure:\n",
    "\n",
    "    1. Chosen name for the experimental folder (e.g \"Tm9_recordings\" or \"Tm9_luminances\")\n",
    "        1.1. \"rawData\" (fixed folder name)\n",
    "            1.1.1 \"alignedData\" (fixed folder name)\n",
    "                1.1.1.1 Folder with date+userID+flyID (e.g. \"2021_09_30_seb_fly1\", from the microscope computer)\n",
    "                    1.1.1.1.1 TSeries (subfolder with recorded TIFFs)\n",
    "                        1.1.1.1.1.1 Motion aligned TIFF stack (generated after motion correction)\n",
    "                        1.1.1.1.1.2 Corresponding stim_output file to this TSeries (e.g.\"_stimulus_output_DATE_TIME\")\n",
    "\n",
    "        1.2 \"analyzed_data\" (fixed folder name)\n",
    "            1.2.1 Stimtype (e.g. \"LocalCircle_5secON_5sec_OFF_120deg_10sec\", folder created by the code)\n",
    "                1.2.1.1 Defined genotype (e.g.\"ExpLine\", folder created by the code)\n",
    "                    1.2.1.1.1 Pickle files (files generated and saved during the analysis, step 7)\n",
    "        1.3 \"stimulus_types\" (fixed folder name)\n",
    "            1.3.1 Different stimulus input files used during the experiment (STIMULUS_NAME.txt files)\n",
    "\n",
    "    2. \"data_save_vars.txt\" (fixed name, text file that lists the variables that want to save in a pickle file, for step 7)\n",
    "    3. \"roi_save_vars.txt\" (fixed name, text file that lists the variables that want to save in a pickle file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd69053-a0c0-481c-9335-c01437593e91",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Region of Interest (ROI) selection\n",
    "\n",
    "Now we can start with the main part of the analysis.\n",
    "First we import everything we need and define the paths for helper functions and the data.\n",
    "Then we define the experimental conditions and load imaging and stimulus information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbe02051-0d9c-419b-9d81-9051194c0aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing needed packages, modules and functions\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import warnings\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import linregress, pearsonr\n",
    "import scipy.stats as stats\n",
    "from sklearn import preprocessing\n",
    "from scipy import ndimage\n",
    "import statsmodels.stats.multicomp as mc\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Importing needed packages, modules and functions, specidif for the course\n",
    "import course_functions.ROI_mod_reduced_msc_course as ROI_mod\n",
    "from course_functions.core_functions_reduced_msc_course import saveWorkspace\n",
    "import course_functions.process_mov_core_reduced_msc_course as pmc\n",
    "import course_functions.post_analysis_core as pac\n",
    "import course_functions.post_analysis_1Hz_gratings_core_msc_course as pag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c4b27cb-a0e6-43f8-ac96-3b79747aa0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the data path\n",
    "dataFolder = r'C:\\MAIN\\FOLDER\\2pData'\n",
    "dataFolder = r'D:\\2pData'\n",
    "save_data = True # choose True or False if you want to save the data and some preliminary plots\n",
    "# Plot related\n",
    "plot_roi_summ = True # choose True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a1276f5-623f-4036-a989-64bac4a54a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Parameters to adjust\n",
    "plt.close('all') # closes all plots that may be still opend\n",
    "\n",
    "# Experimental parameters\n",
    "experiment = 'Tm9_recordings' # same name as the defined experimental folder\n",
    "current_exp_ID = '2022_05_17_user_fly1'\n",
    "current_t_series ='TSeries-05172022_fly1-002'\n",
    "Genotype = 'Tm9-lexA_lexAop-GCamp6f'\n",
    "save_folder_geno = 'Expline'\n",
    "Age = '2-3'\n",
    "Sex = 'f'\n",
    "\n",
    "time_series_stack = 'TSeries-05172022_fly1-002_Ch2_reg.tif'# motion aligned tif stack from Step 1\n",
    "\n",
    "# Analysis parameters\n",
    "analysis_type = 'lumgratings' #stimulus type that was used\n",
    "\n",
    "# Auto-setting of some other directories\n",
    "initialDirectory = os.path.join(dataFolder, experiment)\n",
    "\n",
    "alignedDataDir = os.path.join(initialDirectory,\n",
    "                              'rawData\\\\alignedData')\n",
    "stimInputDir = os.path.join(initialDirectory, 'stimulus_types')\n",
    "saveOutputDir = os.path.join(initialDirectory, 'analyzed_data')\n",
    "summary_save_dir = os.path.join(alignedDataDir,\n",
    "                                '_summaries')\n",
    "trash_folder = os.path.join(dataFolder, 'Trash')\n",
    "\n",
    "# ROI selection/extraction parameters\n",
    "extraction_type = 'manual' # 'SIMA-STICA' 'transfer' 'manual'  Seb: SIMA-STICA for extracting clusters. Tranfer for tranfering the ROI clusters from one sequence to other\n",
    "transfer_type = 'minimal' # 'minimal' 'predefined'\n",
    "transfer_data_name = '2022_05_17_Tm9_fly1-TSeries-05172022_fly2-002_manual.pickle'\n",
    "\n",
    "use_avg_data_for_roi_extract = False\n",
    "use_other_series_roiExtraction = False # ROI selection video\n",
    "roiExtraction_tseries = 'TSeries-05172022_fly1-002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb7cdb3e-6c65-452e-852a-028b4f3dc785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs = 6\n"
     ]
    }
   ],
   "source": [
    "# Get the stimulus and imaging information\n",
    "dataDir = os.path.join(alignedDataDir, current_exp_ID, current_t_series)\n",
    "\n",
    "(time_series, stimulus_information,imaging_information) = \\\n",
    "    pmc.pre_processing_movie (dataDir,stimInputDir,time_series_stack)\n",
    "mean_image = time_series.mean(0)\n",
    "current_movie_ID = current_exp_ID + '-' + current_t_series\n",
    "if save_data:\n",
    "    figure_save_dir = os.path.join(dataDir, 'Results')\n",
    "else: \n",
    "    figure_save_dir = trash_folder\n",
    "\n",
    "if not os.path.exists(figure_save_dir):\n",
    "    os.mkdir(figure_save_dir)\n",
    "experiment_conditions = \\\n",
    "    {'Genotype' : Genotype, 'Age': Age, 'Sex' : Sex,\n",
    "     'FlyID' : current_exp_ID, 'MovieID': current_movie_ID}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09115a7b-9f25-41e9-aab1-8a232d50319d",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    "For you to get familiar with the data we just loaded and with the data we will work with, please take a look at the following dictionaries:\n",
    "- `stimulus_information`\n",
    "- `imaging_information`\n",
    "- `experiment_conditions`\n",
    "and call some of the info in there, e.g. from `stimulus_information`: 'stimtype', 'duration', 'lum'\n",
    "\n",
    "A dictionary is built by having a key and one or several values which can be called by this key. In the cell above we have an example of how it can be constructed (line 15 to 17 for). `experiment_conditions` is the name of the dictionary. `'Genotype', 'Age', 'Sex', 'FlyID'` and `'MovieID'` are the keys of this dictionary. The key is seperated from the value/s with a `:` .\n",
    "By writing the dictionary name in a cell and just running that cell you can see the keys with their corresponding values.\n",
    "By writing the dictionary name followed by square brackets and a key, e.g. `experiment_conditions['Genotype']`, the output will be all the values of this key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "754d378f-3bdb-412f-8867-eba335c1d6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.5, 0.4, 0.3, 0.2, 0.1]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stimulus_information['lum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8d4600d-9ee7-46e4-b9ff-6635d4be21e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizing extraction parameters\n",
    "if transfer_type == 'predefined':\n",
    "    transfer_type = analysis_type\n",
    "    \n",
    "extraction_params = \\\n",
    "    pmc.organize_extraction_params(extraction_type,\n",
    "                               current_t_series=current_t_series,\n",
    "                               current_exp_ID=current_exp_ID,\n",
    "                               alignedDataDir=alignedDataDir,\n",
    "                               stimInputDir=stimInputDir,\n",
    "                               use_other_series_roiExtraction = use_other_series_roiExtraction,\n",
    "                               use_avg_data_for_roi_extract = use_avg_data_for_roi_extract,\n",
    "                               roiExtraction_tseries=roiExtraction_tseries,\n",
    "                               transfer_data_n = transfer_data_name,\n",
    "                               transfer_data_store_dir = saveOutputDir,\n",
    "                               transfer_type = transfer_type,\n",
    "                               imaging_information=imaging_information,\n",
    "                               experiment_conditions=experiment_conditions)\n",
    "        \n",
    "    \n",
    "analysis_params = {'deltaF_method': 'mean',\n",
    "                   'analysis_type': analysis_type} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05b14c14-4fe0-4285-b034-7033cec1000f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'manual'} {'deltaF_method': 'mean', 'analysis_type': 'lumgratings'}\n"
     ]
    }
   ],
   "source": [
    "print (extraction_params, analysis_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a0b46c-8fff-4731-8656-688f3ded550a",
   "metadata": {
    "tags": []
   },
   "source": [
    "The ROI selection we are using is not compatible with jupyter notebook, please run the raw_roi_extraction.py script in either Spyder or Visual Studio Code (VSC).\n",
    "To install VSC follow this link and download the software: https://code.visualstudio.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3e3297-4932-4230-93a0-29722416a3f0",
   "metadata": {},
   "source": [
    "Please get the variabls of the `extracted_rois` dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21d2f4b-dc33-4ab3-9ebc-2674b62df9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickle files with the extracted rois and unpack the roi variables.\n",
    "extracted_roi_dir = summary_save_dir = os.path.join(alignedDataDir, 'extracted_rois')\n",
    "os.chdir(extracted_roi_dir)\n",
    "extracted_roi_file = f'{current_movie_ID}_{extraction_params[\"type\"]}_extracted_rois.pickle'\n",
    "extracted_rois = pickle.load(open(extracted_roi_file, 'rb'))\n",
    "\n",
    "cat_masks = extracted_rois['cat_masks']\n",
    "cat_names = extracted_rois['cat_names']\n",
    "roi_masks = extracted_rois['roi_masks']\n",
    "all_rois_image = extracted_rois['all_rois_image']\n",
    "rois = extracted_rois['rois']\n",
    "threshold_dict = extracted_rois['threshold_dict']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4a1bd8",
   "metadata": {},
   "source": [
    "### 4. Background subtraction\n",
    "In the step before you selected regions of interest, which are axon terminals of Tm9 neurons. In addition you selected a region which did not have any neurons or other structures in it, the background (bg). Now this background will be subtracted from the whole recording to reduce any noise signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b129df2c-05bc-4d2c-9bfc-32b69af8ae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mask for background, needed for bg subtration later\n",
    "for idx, cat_name in enumerate(cat_names):\n",
    "    if cat_name.lower() == 'bg\\r': # Seb: added '\\r' for debugging mode\n",
    "        bg_mask = cat_masks[idx]\n",
    "        continue\n",
    "    elif cat_name.lower() == 'bg': \n",
    "        bg_mask = cat_masks[idx]\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa123d6-2442-4af3-b195-ebb124f7ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ROI_bg instances\n",
    "if rois == None:\n",
    "    del rois\n",
    "    rois = ROI_mod.generate_ROI_instances(roi_masks, cat_masks, cat_names,\n",
    "                                          mean_image, \n",
    "                                          experiment_info = experiment_conditions, \n",
    "                                          imaging_info =imaging_information)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01bfc59-543e-4245-ac74-835343d1a750",
   "metadata": {},
   "source": [
    "Please look at different elements of the rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd3a586-5fb1-4fee-bbde-e973742d6d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task print some instances of the class rois e.g experiment_info, imaging_info, mask, source_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5de123c-495c-42d1-9e46-5cd106adb66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% # BG subtraction\n",
    "time_series = np.transpose(np.subtract(np.transpose(time_series),\n",
    "                                       time_series[:,bg_mask].mean(axis=1)))\n",
    "print('\\n Background subtraction done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a92b845-8825-4e39-92da-15bf66585a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% # ROI trial separated responses\n",
    "(wholeTraces_allTrials_ROIs, respTraces_allTrials_ROIs,\n",
    " baselineTraces_allTrials_ROIs) = \\\n",
    "    pmc.separate_trials_ROI_v4(time_series,rois,stimulus_information,\n",
    "                               imaging_information['frame_rate'],\n",
    "                               df_method = analysis_params['deltaF_method'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0d4abd-b985-4ba9-9dd2-88cace5660e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Append relevant information and calculate some parameters\n",
    "list(map(lambda roi: roi.appendStimInfo(stimulus_information), rois))\n",
    "list(map(lambda roi: roi.findMaxResponse_all_epochs(), rois))\n",
    "list(map(lambda roi: roi.setSourceImage(mean_image), rois))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21d7b3a-1a6d-485f-a43e-364d556eff69",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5. dF/F calculation and trial average\n",
    "\n",
    "In this step the change in flourescence delta F (dF) at a time point t will be normalized to the baseline fluorescence F (or F0): **dF/F = (F(t)-F0)/F0**\n",
    "By calculating dF/F, the responses of different neurons and different flies are comparable now and in addition, noise can be reduced.\n",
    "\n",
    "During trial averaging, we combine the data aquired in one recording for different trials (when the same stimulus sequence is repeated for several times (here 5 times)) and take the average data for each epoch (stimulus occurence, e.g each different luminanc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c227ed4-7cd5-46db-83a8-8433b2ec322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% df/f calculation and trial average \n",
    "(_, respTraces_SNR, baseTraces_SNR) = \\\n",
    "    pmc.separate_trials_ROI_v4(time_series,rois,stimulus_information,\n",
    "                               imaging_information['frame_rate'],\n",
    "                               df_method = analysis_params['deltaF_method'],\n",
    "                               df_use=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684fa05d-b9a0-4e92-9f56-b6ea55f5d1e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 6. SNR (Signal to Noise Ratio) and Reliability calculation\n",
    "\n",
    "These two values are used to filter out ROIs that do not respond at all or in any regards to the stimulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c97d409-76af-478a-a84b-a8afa1ef50c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% SNR and reliability\n",
    "if stimulus_information['random'] == 2:\n",
    "    epoch_to_exclude = None\n",
    "    baseTraces_SNR = respTraces_SNR.copy()\n",
    "    # baseTraces_SNR[]\n",
    "elif stimulus_information['random'] == 0:\n",
    "    epoch_to_exclude = stimulus_information['baseline_epoch']\n",
    "else:\n",
    "    epoch_to_exclude = None\n",
    "\n",
    "[SNR_rois, corr_rois] = pmc.calculate_SNR_Corr(baseTraces_SNR,\n",
    "                                               respTraces_SNR,rois,\n",
    "                                               epoch_to_exclude=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1895bb88-e109-4009-a8a6-576ffb835106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Thresholding\n",
    "if threshold_dict is None:\n",
    "    print('No threshold used, all ROIs will be retained')\n",
    "    thresholded_rois = rois\n",
    "else:\n",
    "    print('Thresholding ROIs')\n",
    "    thresholded_rois = ROI_mod.threshold_ROIs(rois, threshold_dict)\n",
    "\n",
    "final_rois = thresholded_rois\n",
    "final_roi_image = ROI_mod.get_masks_image(final_rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109af445-0e38-4ffc-997d-f87141879f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Plotting ROIs and properties\n",
    "pmc.plot_roi_masks(final_roi_image,mean_image,len(final_rois),\n",
    "                   current_movie_ID,save_fig=True,\n",
    "                   save_dir=figure_save_dir,alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9620efb1-4f24-4aa8-81dd-cf41661031c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 7. Analysis by stimulus type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d1999-7504-48f4-8ff2-2bf84ab0d96c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%% Run desired analyses for different types\n",
    "final_rois = pmc.run_analysis(analysis_params,final_rois,experiment_conditions,\n",
    "                              imaging_information,summary_save_dir,\n",
    "                              save_fig=True,fig_save_dir = figure_save_dir,\n",
    "                              exp_ID=('%s_%s' % (current_movie_ID,\n",
    "                                                 extraction_params['type'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af18cd2-dfea-465d-bc29-444ba0078a34",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%% Make figures for experiment summary and figure to show reliability and SNR plot\n",
    "images = []\n",
    "(properties, colormaps, vminmax, data_to_extract) = \\\n",
    "    pmc.select_properties_plot(final_rois , analysis_params['analysis_type'])\n",
    "for prop in properties:\n",
    "    images.append(ROI_mod.generate_colorMasks_properties(final_rois, prop))\n",
    "pmc.plot_roi_properties(images, properties, colormaps, mean_image,\n",
    "                        vminmax,current_movie_ID, imaging_information['depth'],\n",
    "                        save_fig=True, save_dir=figure_save_dir,figsize=(8, 6),\n",
    "                        alpha=0.5)\n",
    "final_roi_data = ROI_mod.data_to_list(final_rois, data_to_extract)\n",
    "rois_df = pd.DataFrame.from_dict(final_roi_data)\n",
    "\n",
    "pmc.plot_df_dataset(rois_df,data_to_extract,\n",
    "                    exp_ID=('%s_%s' % (current_movie_ID,\n",
    "                                       extraction_params['type'])),\n",
    "                    save_fig=True, save_dir=figure_save_dir)\n",
    "#plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d6141d-1f1a-4443-ad6d-b12dec9b6151",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 8. Save analysed data\n",
    "\n",
    "Now the data is saved in a pickle file. Each ROI will be its own dictionary with all the generated data as keys and values inside. Every fly/ TSeries/ recording will have its own pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca7e3b5-df48-46b3-b224-2cd71edc52ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "saveOutputDir = os.path.join(initialDirectory, 'analyzed_data')\n",
    "if save_data:\n",
    "    os.chdir(dataFolder) # Seb: data_save_vars.txt file needs to be there    \n",
    "    varDict = locals()\n",
    "    pckl_save_name = ('%s_%s' % (current_movie_ID, extraction_params['type']))\n",
    "    saveOutputDir = os.path.join(saveOutputDir, varDict['varDict']['stimulus_information']['stim_name'][:-4]) #Seb: experiment_folder/analyzed_data/stim_name/genotype_folder\n",
    "    if not os.path.exists(saveOutputDir):\n",
    "            os.mkdir(saveOutputDir) # Seb: creating stim_folder\n",
    "    saveOutputDir = os.path.join(saveOutputDir,save_folder_geno)\n",
    "    if not os.path.exists(saveOutputDir):\n",
    "            os.mkdir(saveOutputDir) # Seb: creating genotype_folder\n",
    "    saveWorkspace(saveOutputDir,pckl_save_name, varDict, \n",
    "               varFile='data_save_vars.txt',extension='.pickle')\n",
    "\n",
    "    print('\\n\\n%s saved...\\n\\n' % pckl_save_name)\n",
    "else:\n",
    "    print('Pickle data not created')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92fa882-67f0-4242-abc4-1c677ada1c6f",
   "metadata": {},
   "source": [
    "### 9. Ploting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a27fb6-ba48-4bf6-8ce7-3f94612fed4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (f'Here is the saved pickle file:\\n {saveOutputDir}\\n')\n",
    "data_dir = saveOutputDir\n",
    "results_save_dir = os.path.join(saveOutputDir ,'results')\n",
    "if not os.path.exists(results_save_dir):\n",
    "    os.mkdir(results_save_dir)\n",
    "    \n",
    "print (f'And here we will save the plots that are generated in the last step:\\n {results_save_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1778ed11-20f1-49a6-a7fe-c67274e1a8a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_only_cat = True\n",
    "noisy_grating_analysis = False\n",
    "stimulusFolder = 'Gratings_sine_wave_30sw_30deg_sec_1hz_4sec_static_GRAY_4sec_moving_5_luminances_0.1_0.5_40sec'\n",
    "\n",
    "# Loading data and some parameters\n",
    "polarity_dict, cat_dict = pag.get_polarity_and_cat_dict()\n",
    "all_rois, combined_df, tunings, z_tunings, baselines, baseline_power, _variable = pag.load_pickle_data (data_dir, noisy_grating_analysis, stimulusFolder)\n",
    "all_rois, combined_df, tunings, z_tunings, baselines, baseline_power = pag.concatinate_flies (all_rois, combined_df, tunings, z_tunings, baselines, baseline_power)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714448b9-0f14-43b9-b211-2134aa3e1aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3604ac6-7432-4d0a-bf37-7ac48e0c195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define color dict\n",
    "_, colors = pac.run_matplotlib_params()\n",
    "c_dict = {k:colors[k] for k in colors if k in combined_df['Geno'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffebc37-155f-4bc4-b581-fa0a6ea16ba0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "for idx, geno in enumerate(np.unique(combined_df['Geno'])):\n",
    "   \n",
    "    geno_color = c_dict[geno] #  colors[genotype_colors[0]]\n",
    "    save_n = '{g}_raw'.format(g=geno)\n",
    "    neuron_save_dir = os.path.join(results_save_dir,save_n) #directory where this plot is saved\n",
    "    if not os.path.exists(neuron_save_dir): #if it does not exist jet, make a folder\n",
    "        os.mkdir(neuron_save_dir)\n",
    "    \n",
    "    curr_neuron_mask = pag.plot_only_cat_params(plot_only_cat, cat_dict, combined_df, geno, polarity_dict)\n",
    "    \n",
    "    curr_rois = all_rois[curr_neuron_mask]\n",
    "    for idx, roi in enumerate(curr_rois):\n",
    "        \n",
    "        fig = plt.figure(figsize=(16, 3))\n",
    "        plt.plot(roi.conc_resp,color = geno_color)\n",
    "        save_name = '{geno}_ROI_{n}'.format(geno=geno,n=idx)\n",
    "        plt.title('baseline_slope: {bs}'.format(bs=roi.base_slope))\n",
    "        os.chdir(neuron_save_dir)\n",
    "        plt.savefig('%s.png' % save_name, bbox_inches='tight')\n",
    "        plt.savefig('%s.pdf' % save_name, bbox_inches='tight')\n",
    "        #plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58eb529-0313-4b05-869a-3ffcf1bc9103",
   "metadata": {},
   "source": [
    "Please plot different parameters of the data, e.g:\n",
    "- df_trace\n",
    "- raw_trace\n",
    "\n",
    "What do you see when you compare these two traces?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed74f6e0-ca6e-452c-a43c-8adabbb69cbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 3))\n",
    "plt.plot(roi.df_trace,color = geno_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff563a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 3))\n",
    "plt.plot(roi.raw_trace,color = geno_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e4b27-b57a-4377-8c1f-e1e9db0e5714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing a function\n",
    "\n",
    "def calculate_data_to_plot (plot_only_cat, cat_dict, combined_df, geno, polarity_dict, all_rois, tuning_c, mean_type):\n",
    "    curr_neuron_mask = pag.plot_only_cat_params(plot_only_cat, cat_dict, combined_df, geno, polarity_dict)\n",
    "    curr_df = combined_df[curr_neuron_mask]\n",
    "\n",
    "    diff_luminances = all_rois[curr_neuron_mask][0].luminances\n",
    "    sensitivities = tunings[curr_neuron_mask]\n",
    "    properties = ['Luminance', 'Response']\n",
    "    senst_df = pd.DataFrame(columns=properties)\n",
    "    \n",
    "    tuning_curves = tuning_c[curr_neuron_mask]\n",
    "    \n",
    "    a=pac.compute_over_samples_groups(data = tuning_curves, \n",
    "                                group_ids= np.array(combined_df[curr_neuron_mask]['flyIDNum']), \n",
    "                                error ='SEM',\n",
    "                                experiment_ids = np.array(combined_df[curr_neuron_mask]['Geno']))\n",
    "\n",
    "    label = '{g} n: {f}({ROI})'.format(g=geno,\n",
    "                                       f=len(a['experiment_ids'][geno]['over_samples_means']),\n",
    "                                       ROI=len(a['experiment_ids'][geno]['all_samples']))\n",
    "    \n",
    "    if mean_type == 'groups':        \n",
    "        all_mean_data = a['experiment_ids'][geno]['over_groups_mean']\n",
    "        print(geno,all_mean_data)\n",
    "        all_yerr = a['experiment_ids'][geno]['over_groups_error']\n",
    "    elif mean_type == 'samples':\n",
    "        mean_flies = np.array(a['experiment_ids'][geno]['over_samples_means'])\n",
    "        #mean_flies= mean_flies/mean_flies.max(1).reshape(mean_flies.shape[0],1) # For normalization, uncomment\n",
    "        all_mean_data = mean_flies.mean(0)\n",
    "        all_yerr = mean_flies.std(0)/np.sqrt(mean_flies.shape[0])\n",
    "    \n",
    "    return (all_mean_data, all_yerr, diff_luminances, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ee6c40-3a96-4ba9-8088-8ddb3aa10bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plotting 1 Hz response\n",
    "\n",
    "for idx, geno in enumerate(np.unique(combined_df['Geno'])):\n",
    "    geno_color = c_dict[geno] #  colors[genotype_colors[0]]\n",
    "    neuron_save_dir = os.path.join(results_save_dir,'sine1Hz')\n",
    "    if not os.path.exists(neuron_save_dir):\n",
    "        os.mkdir(neuron_save_dir)\n",
    "        \n",
    "    all_mean_data, all_yerr, diff_luminances, label = calculate_data_to_plot (plot_only_cat, cat_dict, combined_df, geno, polarity_dict, all_rois,tuning_c=tunings, mean_type='groups')\n",
    "    \n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    grid = plt.GridSpec(1, 1, wspace=0.3, hspace=1)\n",
    "    ax1=plt.subplot(grid[0,0])\n",
    "    ax1.errorbar(diff_luminances,all_mean_data,all_yerr,\n",
    "                 fmt='-s',alpha=1,color=geno_color,label=label)\n",
    "    ax1.set_ylim((0,ax1.get_ylim()[1]))\n",
    "    ax1.set_title('1Hz response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1025dd-e679-4cb1-afbd-3e9116f38e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 3))\n",
    "grid = plt.GridSpec(1,2, wspace=0.3, hspace=1)\n",
    "\n",
    "ax1=plt.subplot(grid[0,0])\n",
    "ax2=plt.subplot(grid[0,1])\n",
    "\n",
    "for idx, geno in enumerate(np.unique(combined_df['Geno'])):\n",
    "    geno_color = c_dict[geno] # colors[genotype_colors[idx]] \n",
    "    \n",
    "    all_mean_data, all_yerr, diff_luminances, label = calculate_data_to_plot (plot_only_cat, cat_dict, combined_df, geno, polarity_dict, all_rois,tuning_c=tunings, mean_type='groups')\n",
    "    \n",
    "    ax1.errorbar(diff_luminances,all_mean_data,all_yerr,\n",
    "                 fmt='-o',alpha=.8,color=geno_color,label=label)\n",
    "    \n",
    "    \n",
    "    # AX2\n",
    "    all_mean_data, all_yerr, diff_luminances, label = calculate_data_to_plot (plot_only_cat, cat_dict, combined_df, geno, polarity_dict, all_rois,tuning_c=baselines, mean_type='groups')\n",
    "\n",
    "    ax2.errorbar(diff_luminances,all_mean_data,all_yerr,\n",
    "                 fmt='-o',alpha=.8,color=geno_color,label=label)\n",
    "    \n",
    "ax1.set_ylim((0,ax1.get_ylim()[1]))\n",
    "ax1.set_title('1Hz response')\n",
    "ax1.legend(loc=4)\n",
    "ax1.set_ylabel('Power (a.u.)')\n",
    "ax1.set_xlabel(_variable)\n",
    "\n",
    "ax2.set_ylim((0,ax2.get_ylim()[1]))\n",
    "ax2.set_title('Mean response')\n",
    "ax2.legend(loc=4)\n",
    "ax2.set_ylabel('dF/F')\n",
    "ax2.set_xlabel(_variable)\n",
    "\n",
    "\n",
    "save_name = 'Summary_1hz_mean_resp'.format(geno=geno)\n",
    "os.chdir(neuron_save_dir)\n",
    "plt.savefig('%s.pdf' % save_name, bbox_inches='tight',dpi=300) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78722aec-cb25-4689-bcfc-4638f9059ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heat plots for mean response\n",
    "for idx, geno in enumerate(np.unique(combined_df['Geno'])):\n",
    "    if not(geno[:3] in ['L2_','L3_','Tm9','Tm1','Mi1']):\n",
    "        continue\n",
    "    \n",
    "    curr_neuron_mask = pag.plot_only_cat_params(plot_only_cat, cat_dict, combined_df, geno, polarity_dict)\n",
    "    curr_df = combined_df[curr_neuron_mask]\n",
    "    \n",
    "    mean_baselines = baselines[curr_neuron_mask]\n",
    "    \n",
    "    fig = plt.figure(figsize=(4, 6))\n",
    "    # Baseline tunings\n",
    "    plot_sens = (mean_baselines/mean_baselines.max(axis=1).reshape(mean_baselines.shape[0],1))\n",
    "    sns.heatmap(plot_sens,cmap='Reds',vmin=0,vmax=1)\n",
    "    plt.title('Mean responses {g}'.format(g=geno))\n",
    "    plt.ylabel('ROIs')\n",
    "    plt.xlabel('Epochs')\n",
    "    \n",
    "save_name = 'Heat_map_mean_response_Tm9'.format(geno=geno)\n",
    "os.chdir(neuron_save_dir)\n",
    "plt.savefig('%s.pdf' % save_name, bbox_inches='tight',dpi=300) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f0b790-2c6b-48a9-aa46-10b6aae44cdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (curr_neuron_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
